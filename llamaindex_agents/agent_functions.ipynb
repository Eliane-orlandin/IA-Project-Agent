{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.groq import Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "llm = Groq(model=\"llama-3.3-70b-versatile\", api_key=os.environ.get(\"GROQ_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_imposto_renda(rendimento:float) -> str:\n",
    "    \"\"\" \n",
    "    Calcula o imposto de renda com base no rendimento anual.\n",
    "    Args:\n",
    "        rendimento (float): Rendimento anual do contribuinte.\n",
    "    Returns:\n",
    "        str: O valor do imposto devido com base no rendimento.\n",
    "    \"\"\"\n",
    "    if rendimento <= 2000:\n",
    "        return \"Isento de imposto de renda.\"\n",
    "    elif 2000 < rendimento <= 5000:\n",
    "        imposto = (rendimento - 2000) * 0.10\n",
    "        return f\"Imposto devido é de: R$ {imposto:.2f}, base em um rendimento de R$ {rendimento:.2f}.\"\n",
    "    elif 5000 < rendimento <= 10000:\n",
    "        imposto = (rendimento - 5000) * 0.15 + 300\n",
    "        return f\"Imposto devido é de: R$ {imposto:.2f}, base em um rendimento de R$ {rendimento:.2f}.\"\n",
    "    else:\n",
    "        imposto = (rendimento - 10000) * 0.20 + 1050\n",
    "        return f\"Imposto devido é de: R$ {imposto:.2f}, base em um rendimento de R$ {rendimento:.2f}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertendo Função em Ferramenta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ferramenta_imposto_renda = FunctionTool.from_defaults(\n",
    "    fn=calcular_imposto_renda,\n",
    "    name=\"Calcular Imposto de Renda\",\n",
    "    description=(\n",
    "    \"Calcula o imposto de renda com base no rendimento anual do contribuinte.\"\n",
    "    \"Argumento: redimento (float).\"\n",
    "    \"Retorna o valor do imposto devido de acordo com faixas de rendimento.\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import FunctionCallingAgentWorker "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_worker_imposto = FunctionCallingAgentWorker.from_tools(\n",
    "    tools=[ferramenta_imposto_renda],\n",
    "    verbose=True,\n",
    "    allow_parallel_tool_calls=True,\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import AgentRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_imposto= AgentRunner(agent_worker_imposto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: \n",
      "    Qual é o imposto de renda devido por uma pessoa com rendimento anual de R$ 7500?\n",
      "\n",
      "=== Calling Function ===\n",
      "Calling function: Calcular Imposto de Renda with args: {\"rendimento\": 7500}\n",
      "=== Function Output ===\n",
      "Imposto devido é de: R$ 675.00, base em um rendimento de R$ 7500.00.\n",
      "=== LLM Response ===\n",
      "O imposto de renda devido por uma pessoa com rendimento anual de R$ 7500 é de R$ 675,00.\n"
     ]
    }
   ],
   "source": [
    "response = agent_imposto.chat(\"\"\"\n",
    "    Qual é o imposto de renda devido por uma pessoa com rendimento anual de R$ 7500?\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv \n",
    "\n",
    "def consulta_artigos(titulo: str) -> str:\n",
    "    \"\"\" Consulta artigos na base de dados arXiv e retorna resultados formatados.\"\"\"\n",
    "    busca = arxiv.Search(\n",
    "        query=titulo,\n",
    "        max_results=5,\n",
    "        sort_by=arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "\n",
    "    resultados = [\n",
    "        f\"Título: {artigo.title}\\n\"\n",
    "        f\"Categoria: {artigo.primary_category}\\n\"\n",
    "        f\"Link: {artigo.entry_id}\\n\"\n",
    "        for artigo in busca.results()\n",
    "    ]\n",
    "\n",
    "    return \"\\n\\n\".join(resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "consulta_artigos_tool = FunctionTool.from_defaults(fn=consulta_artigos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    [ferramenta_imposto_renda, consulta_artigos_tool],\n",
    "    verbose=True,\n",
    "    allow_parallel_tool_calls=False,\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Me retorne artigos sobre LangChain na eeducação\n",
      "=== Calling Function ===\n",
      "Calling function: consulta_artigos with args: {\"titulo\": \"LangChain na educa\\u00e7\\u00e3o\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5z/bv195b9d0f11m9c66rw80j3r0000gp/T/ipykernel_6535/3605877752.py:15: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
      "  for artigo in busca.results()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Function Output ===\n",
      "Título: Development and Testing of Retrieval Augmented Generation in Large Language Models -- A Case Study Report\n",
      "Categoria: cs.CL\n",
      "Link: http://arxiv.org/abs/2402.01733v1\n",
      "\n",
      "\n",
      "Título: From Prompt Injections to SQL Injection Attacks: How Protected is Your LLM-Integrated Web Application?\n",
      "Categoria: cs.CR\n",
      "Link: http://arxiv.org/abs/2308.01990v4\n",
      "\n",
      "\n",
      "Título: Automating Customer Service using LangChain: Building custom open-source GPT Chatbot for organizations\n",
      "Categoria: cs.CL\n",
      "Link: http://arxiv.org/abs/2310.05421v1\n",
      "\n",
      "\n",
      "Título: Poisoned LangChain: Jailbreak LLMs by LangChain\n",
      "Categoria: cs.CL\n",
      "Link: http://arxiv.org/abs/2406.18122v1\n",
      "\n",
      "\n",
      "Título: Breast Ultrasound Report Generation using LangChain\n",
      "Categoria: eess.IV\n",
      "Link: http://arxiv.org/abs/2312.03013v1\n",
      "\n",
      "=== Calling Function ===\n",
      "Calling function: consulta_artigos with args: {\"titulo\": \"LangChain e educa\\u00e7\\u00e3o\"}\n",
      "=== Function Output ===\n",
      "Título: From Prompt Injections to SQL Injection Attacks: How Protected is Your LLM-Integrated Web Application?\n",
      "Categoria: cs.CR\n",
      "Link: http://arxiv.org/abs/2308.01990v4\n",
      "\n",
      "\n",
      "Título: Automating Customer Service using LangChain: Building custom open-source GPT Chatbot for organizations\n",
      "Categoria: cs.CL\n",
      "Link: http://arxiv.org/abs/2310.05421v1\n",
      "\n",
      "\n",
      "Título: Poisoned LangChain: Jailbreak LLMs by LangChain\n",
      "Categoria: cs.CL\n",
      "Link: http://arxiv.org/abs/2406.18122v1\n",
      "\n",
      "\n",
      "Título: Breast Ultrasound Report Generation using LangChain\n",
      "Categoria: eess.IV\n",
      "Link: http://arxiv.org/abs/2312.03013v1\n",
      "\n",
      "\n",
      "Título: Revolutionizing Mental Health Care through LangChain: A Journey with a Large Language Model\n",
      "Categoria: cs.HC\n",
      "Link: http://arxiv.org/abs/2403.05568v1\n",
      "\n",
      "=== Calling Function ===\n",
      "Calling function: consulta_artigos with args: {\"titulo\": \"LangChain aplicado \\u00e0 educa\\u00e7\\u00e3o\"}\n",
      "=== Function Output ===\n",
      "Título: From Prompt Injections to SQL Injection Attacks: How Protected is Your LLM-Integrated Web Application?\n",
      "Categoria: cs.CR\n",
      "Link: http://arxiv.org/abs/2308.01990v4\n",
      "\n",
      "\n",
      "Título: Método de elementos finitos aplicado a las ecuaciones de Stokes y de Advección-Difusión\n",
      "Categoria: math.NA\n",
      "Link: http://arxiv.org/abs/1401.7619v1\n",
      "\n",
      "\n",
      "Título: Método de Monte Carlo aplicado ao Cálculo Fracionário\n",
      "Categoria: math.NA\n",
      "Link: http://arxiv.org/abs/2110.08129v1\n",
      "\n",
      "\n",
      "Título: Automating Customer Service using LangChain: Building custom open-source GPT Chatbot for organizations\n",
      "Categoria: cs.CL\n",
      "Link: http://arxiv.org/abs/2310.05421v1\n",
      "\n",
      "\n",
      "Título: Poisoned LangChain: Jailbreak LLMs by LangChain\n",
      "Categoria: cs.CL\n",
      "Link: http://arxiv.org/abs/2406.18122v1\n",
      "\n",
      "=== LLM Response ===\n",
      "Infelizmente, não há resultados que relacionem LangChain com a educação.\n"
     ]
    }
   ],
   "source": [
    "agent = AgentRunner(agent_worker)\n",
    "response = agent.chat(\"Me retorne artigos sobre LangChain na eeducação\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando o Tavily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_key = os.environ.get(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools.tavily_research import TavilyToolSpec\n",
    "\n",
    "tavily_tool = TavilyToolSpec(\n",
    "    api_key=tavily_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search\n"
     ]
    }
   ],
   "source": [
    "tavily_tool_list = tavily_tool.to_tool_list()\n",
    "for tool in tavily_tool_list:\n",
    "    print(tool.metadata.name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id_='700faef2-bc7e-4be1-8d7a-31894b828314', embedding=None, metadata={'url': 'https://community.revelo.com.br/faca-perguntas-ao-seu-pdf-usando-langchain-llama-2-e-python/'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Durante 2023, a Meta anunciou o LLaMA 2 (de agora em diante vou chamá-lo simplesmente de Llama 2), um LLM de código aberto que é a evolução de seu modelo anterior (LLaMA 1), que pode ser usado para criar aplicações para fins comerciais. Para carregar o modelo Llama 2, como aconteceu com o carregamento de PDF e Pinecode, LangChain também nos fornece uma interface (que fácil!). Isto não significa que devolva dois parágrafos ou duas palavras, mas tem a ver com os textos que o modelo considera significativos para fornecer uma resposta: e um documento pode conter vários parágrafos. O que se vê neste artigo é apenas um vislumbre das capacidades do LangChain, já que possui muitas outras integrações e, além disso, permite que seja utilizado —através dos plugins— com outros modelos como ChatGPT.', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tavily_tool.search(\"Me rteorne artigos científicos sobre LangChain\", max_results=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
