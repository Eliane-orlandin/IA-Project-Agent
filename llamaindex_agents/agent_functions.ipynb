{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elianeorlandin/Documents/Desenvolvimento/IA-Project-Agent/llamaindex_agents/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.groq import Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "llm = Groq(model=\"llama-3.3-70b-versatile\", api_key=os.environ.get(\"GROQ_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_imposto_renda(rendimento:float) -> str:\n",
    "    \"\"\" \n",
    "    Calcula o imposto de renda com base no rendimento anual.\n",
    "    Args:\n",
    "        rendimento (float): Rendimento anual do contribuinte.\n",
    "    Returns:\n",
    "        str: O valor do imposto devido com base no rendimento.\n",
    "    \"\"\"\n",
    "    if rendimento <= 2000:\n",
    "        return \"Isento de imposto de renda.\"\n",
    "    elif 2000 < rendimento <= 5000:\n",
    "        imposto = (rendimento - 2000) * 0.10\n",
    "        return f\"Imposto devido é de: R$ {imposto:.2f}, base em um rendimento de R$ {rendimento:.2f}.\"\n",
    "    elif 5000 < rendimento <= 10000:\n",
    "        imposto = (rendimento - 5000) * 0.15 + 300\n",
    "        return f\"Imposto devido é de: R$ {imposto:.2f}, base em um rendimento de R$ {rendimento:.2f}.\"\n",
    "    else:\n",
    "        imposto = (rendimento - 10000) * 0.20 + 1050\n",
    "        return f\"Imposto devido é de: R$ {imposto:.2f}, base em um rendimento de R$ {rendimento:.2f}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertendo Função em Ferramenta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ferramenta_imposto_renda = FunctionTool.from_defaults(\n",
    "    fn=calcular_imposto_renda,\n",
    "    name=\"Calcular Imposto de Renda\",\n",
    "    description=(\n",
    "    \"Calcula o imposto de renda com base no rendimento anual do contribuinte.\"\n",
    "    \"Argumento: redimento (float).\"\n",
    "    \"Retorna o valor do imposto devido de acordo com faixas de rendimento.\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import FunctionCallingAgentWorker "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_worker_imposto = FunctionCallingAgentWorker.from_tools(\n",
    "    tools=[ferramenta_imposto_renda],\n",
    "    verbose=True,\n",
    "    allow_parallel_tool_calls=True,\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import AgentRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_imposto= AgentRunner(agent_worker_imposto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: \n",
      "    Qual é o imposto de renda devido por uma pessoa com rendimento anual de R$ 7500?\n",
      "\n",
      "=== Calling Function ===\n",
      "Calling function: Calcular Imposto de Renda with args: {\"rendimento\": 7500}\n",
      "=== Function Output ===\n",
      "Imposto devido é de: R$ 675.00, base em um rendimento de R$ 7500.00.\n",
      "=== LLM Response ===\n",
      "O imposto de renda devido por uma pessoa com rendimento anual de R$ 7500 é de R$ 675,00.\n"
     ]
    }
   ],
   "source": [
    "response = agent_imposto.chat(\"\"\"\n",
    "    Qual é o imposto de renda devido por uma pessoa com rendimento anual de R$ 7500?\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv \n",
    "\n",
    "def consulta_artigos(titulo: str) -> str:\n",
    "    \"\"\" Consulta artigos na base de dados arXiv e retorna resultados formatados.\"\"\"\n",
    "    busca = arxiv.Search(\n",
    "        query=titulo,\n",
    "        max_results=5,\n",
    "        sort_by=arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "\n",
    "    resultados = [\n",
    "        f\"Título: {artigo.title}\\n\"\n",
    "        f\"Categoria: {artigo.primary_category}\\n\"\n",
    "        f\"Link: {artigo.entry_id}\\n\"\n",
    "        for artigo in busca.results()\n",
    "    ]\n",
    "\n",
    "    return \"\\n\\n\".join(resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "consulta_artigos_tool = FunctionTool.from_defaults(fn=consulta_artigos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    [ferramenta_imposto_renda, consulta_artigos_tool],\n",
    "    verbose=True,\n",
    "    allow_parallel_tool_calls=False,\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Me retorne artigos sobre LangChain na eeducação\n",
      "=== Calling Function ===\n",
      "Calling function: consulta_artigos with args: {\"titulo\": \"LangChain na educa\\u00e7\\u00e3o\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5z/bv195b9d0f11m9c66rw80j3r0000gp/T/ipykernel_10203/3605877752.py:15: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
      "  for artigo in busca.results()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Function Output ===\n",
      "Título: Development and Testing of Retrieval Augmented Generation in Large Language Models -- A Case Study Report\n",
      "Categoria: cs.CL\n",
      "Link: http://arxiv.org/abs/2402.01733v1\n",
      "\n",
      "\n",
      "Título: From Prompt Injections to SQL Injection Attacks: How Protected is Your LLM-Integrated Web Application?\n",
      "Categoria: cs.CR\n",
      "Link: http://arxiv.org/abs/2308.01990v4\n",
      "\n",
      "\n",
      "Título: Automating Customer Service using LangChain: Building custom open-source GPT Chatbot for organizations\n",
      "Categoria: cs.CL\n",
      "Link: http://arxiv.org/abs/2310.05421v1\n",
      "\n",
      "\n",
      "Título: Poisoned LangChain: Jailbreak LLMs by LangChain\n",
      "Categoria: cs.CL\n",
      "Link: http://arxiv.org/abs/2406.18122v1\n",
      "\n",
      "\n",
      "Título: Breast Ultrasound Report Generation using LangChain\n",
      "Categoria: eess.IV\n",
      "Link: http://arxiv.org/abs/2312.03013v1\n",
      "\n",
      "=== Calling Function ===\n",
      "Calling function: consulta_artigos with args: {\"titulo\": \"LangChain e educa\\u00e7\\u00e3o\"}\n",
      "=== Function Output ===\n",
      "Título: From Prompt Injections to SQL Injection Attacks: How Protected is Your LLM-Integrated Web Application?\n",
      "Categoria: cs.CR\n",
      "Link: http://arxiv.org/abs/2308.01990v4\n",
      "\n",
      "\n",
      "Título: Automating Customer Service using LangChain: Building custom open-source GPT Chatbot for organizations\n",
      "Categoria: cs.CL\n",
      "Link: http://arxiv.org/abs/2310.05421v1\n",
      "\n",
      "\n",
      "Título: Poisoned LangChain: Jailbreak LLMs by LangChain\n",
      "Categoria: cs.CL\n",
      "Link: http://arxiv.org/abs/2406.18122v1\n",
      "\n",
      "\n",
      "Título: Breast Ultrasound Report Generation using LangChain\n",
      "Categoria: eess.IV\n",
      "Link: http://arxiv.org/abs/2312.03013v1\n",
      "\n",
      "\n",
      "Título: Revolutionizing Mental Health Care through LangChain: A Journey with a Large Language Model\n",
      "Categoria: cs.HC\n",
      "Link: http://arxiv.org/abs/2403.05568v1\n",
      "\n",
      "=== Calling Function ===\n",
      "Calling function: consulta_artigos with args: {\"titulo\": \"LangChain aplicado \\u00e0 educa\\u00e7\\u00e3o\"}\n",
      "=== Function Output ===\n",
      "Título: From Prompt Injections to SQL Injection Attacks: How Protected is Your LLM-Integrated Web Application?\n",
      "Categoria: cs.CR\n",
      "Link: http://arxiv.org/abs/2308.01990v4\n",
      "\n",
      "\n",
      "Título: Método de elementos finitos aplicado a las ecuaciones de Stokes y de Advección-Difusión\n",
      "Categoria: math.NA\n",
      "Link: http://arxiv.org/abs/1401.7619v1\n",
      "\n",
      "\n",
      "Título: Método de Monte Carlo aplicado ao Cálculo Fracionário\n",
      "Categoria: math.NA\n",
      "Link: http://arxiv.org/abs/2110.08129v1\n",
      "\n",
      "\n",
      "Título: Automating Customer Service using LangChain: Building custom open-source GPT Chatbot for organizations\n",
      "Categoria: cs.CL\n",
      "Link: http://arxiv.org/abs/2310.05421v1\n",
      "\n",
      "\n",
      "Título: Poisoned LangChain: Jailbreak LLMs by LangChain\n",
      "Categoria: cs.CL\n",
      "Link: http://arxiv.org/abs/2406.18122v1\n",
      "\n",
      "=== LLM Response ===\n",
      "Infelizmente, não foi possível encontrar artigos sobre LangChain aplicado à educação. No entanto, você pode tentar procurar em outras bases de dados ou realizar uma busca mais específica para encontrar resultados mais relevantes. Além disso, é importante notar que a pesquisa sobre LangChain e sua aplicação em diferentes áreas, incluindo a educação, é um campo em constante evolução, e novos estudos e artigos podem ser publicados a qualquer momento.\n"
     ]
    }
   ],
   "source": [
    "agent = AgentRunner(agent_worker)\n",
    "response = agent.chat(\"Me retorne artigos sobre LangChain na eeducação\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando o Tavily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_key = os.environ.get(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools.tavily_research import TavilyToolSpec\n",
    "\n",
    "tavily_tool = TavilyToolSpec(\n",
    "    api_key=tavily_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search\n"
     ]
    }
   ],
   "source": [
    "tavily_tool_list = tavily_tool.to_tool_list()\n",
    "for tool in tavily_tool_list:\n",
    "    print(tool.metadata.name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id_='29cb1e12-0732-4fcc-ba58-101ad8f4f339', embedding=None, metadata={'url': 'https://community.revelo.com.br/faca-perguntas-ao-seu-pdf-usando-langchain-llama-2-e-python/'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Durante 2023, a Meta anunciou o LLaMA 2 (de agora em diante vou chamá-lo simplesmente de Llama 2), um LLM de código aberto que é a evolução de seu modelo anterior (LLaMA 1), que pode ser usado para criar aplicações para fins comerciais. Para carregar o modelo Llama 2, como aconteceu com o carregamento de PDF e Pinecode, LangChain também nos fornece uma interface (que fácil!). Isto não significa que devolva dois parágrafos ou duas palavras, mas tem a ver com os textos que o modelo considera significativos para fornecer uma resposta: e um documento pode conter vários parágrafos. O que se vê neste artigo é apenas um vislumbre das capacidades do LangChain, já que possui muitas outras integrações e, além disso, permite que seja utilizado —através dos plugins— com outros modelos como ChatGPT.', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tavily_tool.search(\"Me rteorne artigos científicos sobre LangChain\", max_results=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definição de ferramentas externas e integração com o agente  \n",
    "Criamos uma ferramenta utilizando a API do Tavily para realizar buscas sobre um determinado tópico.  \n",
    "Essa ferramenta será incorporada ao agente para permitir pesquisas contextuais.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "tavily_tool_function = FunctionTool.from_defaults(\n",
    "    fn=tavily_tool.search,\n",
    "    name=\"Tavily Search\",\n",
    "    description=(\n",
    "        \"Busca artigos com Tavily sobre um determinado tópico\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    tools=[tavily_tool_function],\n",
    "    verbose=True,\n",
    "    allow_parallel_tool_calls=False,\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AgentRunner(agent_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Me retorne artigos sobre LLM e LangChain\n",
      "=== Calling Function ===\n",
      "Calling function: Tavily Search with args: {\"max_results\": 6, \"query\": \"LLM e LangChain\"}\n",
      "=== Function Output ===\n",
      "[Document(id_='8c34e89a-924c-43fc-bd19-0d50e14e8d26', embedding=None, metadata={'url': 'https://www.techtarget.com/searchenterpriseai/tip/How-to-use-LangChain-for-LLM-application-development'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='[LangChain](https://www.techtarget.com/searchenterpriseai/definition/LangChain), an open source framework for building AI applications, has become a de facto standard for working with LLMs and integrating [APIs](https://www.techtarget.com/searchapparchitecture/definition/application-program-interface-API). The tool serves as a critical intermediary, enabling a targeted LLM to interface with traditional software. [...] LangChain enables developers to integrate AI models with standard IT components such as software utilities, APIs and databases. Within LangChain, developers use a combination of prompts, tools and chains to manage LLMs and create desired AI interactions.\\n\\n### Prompts\\n\\nAll processes in LangChain revolve around [prompts](https://www.techtarget.com/searchenterpriseai/definition/AI-prompt), which initiate the tasks that AI applications rely on. [...] Using LangChain with Spark and Kafka\\n------------------------------------\\n\\nLangChain excels at managing LLM workflows and integrating language models with APIs, tools and software utilities. But AI applications often require more than just model orchestration.', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='0fc8abcf-f41b-4ba2-bc70-61fb6a41950a', embedding=None, metadata={'url': 'https://vitiya99.medium.com/building-scalable-llm-applications-with-langchain-and-vector-databases-5541c0ebee0e'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Large Language Models (LLMs) are transforming how we interact with information and build intelligent applications. However, effectively leveraging their power for real-world scenarios often requires extending their capabilities beyond simple prompt-response interactions. This is where LangChain and vector databases come into play. LangChain provides a streamlined framework for developing LLM-powered applications, while vector databases facilitate efficient semantic search, enabling LLMs to [...] LangChain simplifies the complexities of integrating LLMs into applications by providing abstractions for common tasks like prompt management, chain execution, and memory management. Vector databases, such as Pinecone, Weaviate, and Faiss, store embeddings (vector representations of data) generated by models like Sentence Transformers or OpenAI’s embeddings API. This allows for similarity search, enabling the retrieval of contextually relevant information based on semantic meaning rather than [...] keyword matching. The combination of LangChain and vector databases empowers developers to build sophisticated LLM applications that can access, process, and reason over large amounts of unstructured data.', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='c00ed611-1b03-4cf4-8dc8-77a9dd241cee', embedding=None, metadata={'url': 'https://scalexi.medium.com/understanding-the-differences-between-llm-chains-and-llm-agent-executors-in-langchain-3f3cf402442f'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"**LangChain** has emerged as a robust framework for building applications powered by large language models (LLMs). Two fundamental concepts within LangChain are **LLM Chains** and **LLM Agent Executors**, both of which leverage tools to enhance the capabilities of LLMs. While they may seem similar at first glance, understanding their differences is crucial for developers aiming to harness LangChain's full potential. [...] Both **LLM Chains** and **LLM Agent Executors** offer powerful ways to structure and execute tasks using LangChain, but they are designed for different use cases. Understanding the key differences is essential for choosing the right approach.\", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='88498561-b8f8-4e79-b22d-aca3e7dd2392', embedding=None, metadata={'url': 'https://python.langchain.com/docs/integrations/llms/'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Unless you are specifically using more advanced prompting techniques, you are probably looking for [this page instead](https://python.langchain.com/docs/integrations/chat/).\\n\\n[LLMs](https://python.langchain.com/docs/concepts/text_llms/) are language models that take a string as input and return a string as output.\\n\\ninfo [...] [![Image 2: Open on GitHub](https://img.shields.io/badge/Open%20on%20GitHub-grey?logo=github&logoColor=white)](https://github.com/langchain-ai/langchain/blob/master/docs/docs/integrations/llms/index.mdx)\\n\\nLLMs\\n====\\n\\ncaution\\n\\nYou are currently on a page documenting the use of [text completion models](https://python.langchain.com/docs/concepts/text_llms/). Many of the latest and most popular models are [chat completion models](https://python.langchain.com/docs/concepts/chat_models/). [...] *   [Kinetica](https://python.langchain.com/docs/integrations/chat/kinetica/)\\n        *   [Konko](https://python.langchain.com/docs/integrations/chat/konko/)\\n        *   [LiteLLM](https://python.langchain.com/docs/integrations/chat/litellm/)\\n        *   [Llama 2 Chat](https://python.langchain.com/docs/integrations/chat/llama2_chat/)\\n        *   [Llama API](https://python.langchain.com/docs/integrations/chat/llama_api/)', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='999aa9f9-ca32-4830-bc52-7044d316cbce', embedding=None, metadata={'url': 'https://python.langchain.com/docs/tutorials/llm_chain/'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"In this quickstart we'll show you how to build a simple LLM application with LangChain. This application will translate text from English into another language. This is a relatively simple LLM application - it's just a single LLM call plus some prompting. Still, this is a great way to get started with LangChain - a lot of features can be built with just some prompting and an LLM call!\\n\\nAfter reading this tutorial, you'll have a high level overview of: [...] Many of the applications you build with LangChain will contain multiple steps with multiple invocations of LLM calls. As these applications get more and more complex, it becomes crucial to be able to inspect what exactly is going on inside your chain or agent. The best way to do this is with [LangSmith](https://smith.langchain.com/).\\n\\nAfter you sign up at the link above, make sure to set your environment variables to start logging traces: [...] [![Image 1: 🦜️🔗 LangChain](https://python.langchain.com/img/brand/wordmark.png)](https://python.langchain.com/)[Integrations](https://python.langchain.com/docs/integrations/providers/)[API Reference](https://python.langchain.com/api_reference/)\\n\\n[More](https://python.langchain.com/docs/tutorials/llm_chain/#)\", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='d90d9fb5-b2d6-4d4e-96ec-7e303ab941fa', embedding=None, metadata={'url': 'https://vstorm.co/the-power-of-langchain-in-llm-based-applications/'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='LangChain, a framework specifically designed for Large Language Model (LLM) applications, has emerged as a major tool in enhancing the capabilities of natural', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')]\n",
      "=== LLM Response ===\n",
      "Os artigos sobre LLM e LangChain abordam a integração de modelos de linguagem grandes (LLMs) com a framework LangChain para desenvolver aplicações de inteligência artificial (IA) mais avançadas. A LangChain fornece uma estrutura para gerenciar workflows de LLMs e integrá-los com APIs, ferramentas e utilitários de software, permitindo que os desenvolvedores criem aplicações de IA mais complexas e escaláveis.\n",
      "\n",
      "Os artigos destacam a importância da LangChain para simplificar a integração de LLMs em aplicações, fornecendo abstrações para tarefas comuns como gerenciamento de prompts, execução de chains e gerenciamento de memória. Além disso, a combinação da LangChain com bancos de dados de vetores permite a realização de buscas semânticas eficientes, permitindo que os LLMs acessem e processem grandes quantidades de dados não estruturados.\n",
      "\n",
      "Os artigos também discutem a diferença entre LLM Chains e LLM Agent Executors, dois conceitos fundamentais na LangChain, e como eles podem ser usados para estruturar e executar tarefas em aplicações de IA. Além disso, os artigos fornecem exemplos de como a LangChain pode ser usada para desenvolver aplicações de IA, como tradução de texto e busca semântica.\n",
      "\n",
      "Em resumo, os artigos sobre LLM e LangChain destacam a importância da integração de modelos de linguagem grandes com a framework LangChain para desenvolver aplicações de inteligência artificial mais avançadas e escaláveis. A LangChain fornece uma estrutura para gerenciar workflows de LLMs e integrá-los com APIs, ferramentas e utilitários de software, permitindo que os desenvolvedores criem aplicações de IA mais complexas e eficientes.\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"Me retorne artigos sobre LLM e LangChain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os artigos sobre LLM e LangChain abordam a integração de modelos de linguagem grandes (LLMs) com a framework LangChain para desenvolver aplicações de inteligência artificial (IA) mais avançadas. A LangChain fornece uma estrutura para gerenciar workflows de LLMs e integrá-los com APIs, ferramentas e utilitários de software, permitindo que os desenvolvedores criem aplicações de IA mais complexas e escaláveis.\n",
      "\n",
      "Os artigos destacam a importância da LangChain para simplificar a integração de LLMs em aplicações, fornecendo abstrações para tarefas comuns como gerenciamento de prompts, execução de chains e gerenciamento de memória. Além disso, a combinação da LangChain com bancos de dados de vetores permite a realização de buscas semânticas eficientes, permitindo que os LLMs acessem e processem grandes quantidades de dados não estruturados.\n",
      "\n",
      "Os artigos também discutem a diferença entre LLM Chains e LLM Agent Executors, dois conceitos fundamentais na LangChain, e como eles podem ser usados para estruturar e executar tarefas em aplicações de IA. Além disso, os artigos fornecem exemplos de como a LangChain pode ser usada para desenvolver aplicações de IA, como tradução de texto e busca semântica.\n",
      "\n",
      "Em resumo, os artigos sobre LLM e LangChain destacam a importância da integração de modelos de linguagem grandes com a framework LangChain para desenvolver aplicações de inteligência artificial mais avançadas e escaláveis. A LangChain fornece uma estrutura para gerenciar workflows de LLMs e integrá-los com APIs, ferramentas e utilitários de software, permitindo que os desenvolvedores criem aplicações de IA mais complexas e eficientes.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 16 0 (offset 0)\n",
      "Ignoring wrong pointing object 18 0 (offset 0)\n",
      "Ignoring wrong pointing object 20 0 (offset 0)\n",
      "Ignoring wrong pointing object 22 0 (offset 0)\n",
      "Ignoring wrong pointing object 42 0 (offset 0)\n",
      "Ignoring wrong pointing object 50 0 (offset 0)\n",
      "Ignoring wrong pointing object 52 0 (offset 0)\n",
      "Ignoring wrong pointing object 54 0 (offset 0)\n",
      "Ignoring wrong pointing object 56 0 (offset 0)\n",
      "Ignoring wrong pointing object 58 0 (offset 0)\n",
      "Ignoring wrong pointing object 70 0 (offset 0)\n",
      "Ignoring wrong pointing object 72 0 (offset 0)\n",
      "Ignoring wrong pointing object 89 0 (offset 0)\n",
      "Ignoring wrong pointing object 91 0 (offset 0)\n",
      "Ignoring wrong pointing object 103 0 (offset 0)\n",
      "Ignoring wrong pointing object 108 0 (offset 0)\n",
      "Ignoring wrong pointing object 149 0 (offset 0)\n",
      "Ignoring wrong pointing object 155 0 (offset 0)\n",
      "Ignoring wrong pointing object 158 0 (offset 0)\n",
      "Ignoring wrong pointing object 160 0 (offset 0)\n",
      "Ignoring wrong pointing object 163 0 (offset 0)\n",
      "Ignoring wrong pointing object 165 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "url = \"files/LLM.pdf\"\n",
    "artigo = SimpleDirectoryReader(input_files=[url]).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"files/LLM_2.pdf\"\n",
    "tutorial = SimpleDirectoryReader(input_files=[url]).load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gerar os Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name= \"inTfloat/multilingual-e5-large\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "artigo_index = VectorStoreIndex.from_documents(artigo)\n",
    "tutorial_index = VectorStoreIndex.from_documents(tutorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "artigo_index.storage_context.persist(persist_dir=\"artigo\")\n",
    "tutorial_index.storage_context.persist(persist_dir=\"tutorial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engine de Busca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext, load_index_from_storage    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_context = StorageContext.from_defaults(\n",
    "    persist_dir=\"artigo\"\n",
    ")\n",
    "artigo_index = load_index_from_storage(storage_context)\n",
    "\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    persist_dir=\"tutorial\"\n",
    ")\n",
    "tutorial_index = load_index_from_storage(storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "artigo_engine = artigo_index.as_query_engine(similary_top_k=3, llm=llm)\n",
    "tutorial_engine = tutorial_index.as_query_engine(similary_top_k=3, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine_tools = [\n",
    "    QueryEngineTool(\n",
    "        query_engine=artigo_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"artigo_engine\",\n",
    "            description=(\n",
    "                \"Fornece informaçõe4s sobre LLM e LangChain.\"\n",
    "                \"Use uma pergunta detalhada em texto simples como entrada para a ferramenta\"\n",
    "            )\n",
    "        )\n",
    "    ),\n",
    "    QueryEngineTool(\n",
    "        query_engine=tutorial_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"tutorial_engine\",\n",
    "            description=(\n",
    "                \"Fornece informaçõe4s sobre casos de uso e aplicações em LLMs.\"\n",
    "                \"Use uma pergunta detalhada em texto simples como entrada para a ferramenta\"\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    query_engine_tools,\n",
    "    verbose=True,\n",
    "    allow_parallel_tool_calls=True,\n",
    "    llm=llm\n",
    ")\n",
    "agent_document = AgentRunner(agent_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Quais as principais aplicações posso construir com LLMs e LangChain?\n",
      "=== Calling Function ===\n",
      "Calling function: artigo_engine with args: {\"input\": \"Quais as principais aplica\\u00e7\\u00f5es posso construir com LLMs e LangChain?\"}\n",
      "=== Function Output ===\n",
      "Com LLMs, você pode desenvolver aplicativos prontos para produção, como modelos de linguagem personalizados para atender às necessidades específicas do seu domínio. Além disso, você pode ajustar os modelos de código aberto para melhorar o desempenho em seu domínio específico. Isso inclui a capacidade de treinar os modelos com seus dados específicos, permitindo uma maior precisão e controle sobre os resultados. Com a combinação de LLMs e ferramentas como a Databricks, você pode criar soluções personalizadas para suas necessidades, desde a criação de modelos de linguagem até a implementação de soluções de dados.\n",
      "=== Calling Function ===\n",
      "Calling function: tutorial_engine with args: {\"input\": \"Quais as principais aplica\\u00e7\\u00f5es posso construir com LLMs e LangChain?\"}\n",
      "=== Function Output ===\n",
      "As principais aplicações que podem ser construídas com LLMs incluem:\n",
      "\n",
      "1. Criação e aprimoramento de conteúdo, como:\n",
      " * Geração de conteúdo: produção automática de texto\n",
      " * Assistência na redação: correção ortográfica, de estilo e de conteúdo\n",
      " * Tradução automática: conversão de texto de um idioma para outro\n",
      " * Resumo de textos: redução de documentos longos em resumos\n",
      " * Planejamento e roteiro de conteúdo: estruturação do conteúdo\n",
      " * Brainstorming: propostas criativas para projetos, nomes, conceitos, etc.\n",
      " * Programação: criação de código de programação a partir de linguagem natural\n",
      "\n",
      "2. Análise e organização de informações, como:\n",
      " * Análise de sentimento: avaliação de emoções e opiniões em textos\n",
      " * Extração de informações: extração de dados específicos de documentos grandes\n",
      " * Classificação de textos: organização de textos em categorias ou temas específicos\n",
      " * Revisão técnica: assistência na revisão de documentos especializados\n",
      "\n",
      "3. Interação e automação, como:\n",
      " * Chatbots: simulação de conversas sobre tópicos gerais ou específicos\n",
      " * Perguntas e respostas: geração de respostas a perguntas com base em um corpus\n",
      "\n",
      "Além disso, com o surgimento dos LLMs multimodais, outras aplicações estão começando a surgir, como a geração de conteúdo audiovisual, a interpretação de dados de imagens, a tradução de conteúdo multimídia ou a criação de experiências interativas ricas.\n",
      "=== Calling Function ===\n",
      "Calling function: artigo_engine with args: {\"input\": \"Quais as principais aplica\\u00e7\\u00f5es posso construir com LLMs e LangChain?\"}\n",
      "=== Function Output ===\n",
      "Com LLMs, você pode desenvolver aplicativos prontos para produção, como modelos de linguagem personalizados para atender às necessidades específicas do seu domínio. Além disso, você pode ajustar os modelos de código aberto para melhorar o desempenho em seu domínio específico. Isso inclui a capacidade de treinar os modelos com seus dados específicos, permitindo uma maior precisão e controle sobre os resultados. Com a combinação de LLMs e ferramentas como a Databricks, você pode criar soluções personalizadas para suas necessidades, desde a criação de modelos de linguagem até a implementação de soluções de inteligência artificial em sua organização.\n",
      "=== Calling Function ===\n",
      "Calling function: tutorial_engine with args: {\"input\": \"Quais as principais aplica\\u00e7\\u00f5es posso construir com LLMs e LangChain?\"}\n",
      "=== Function Output ===\n",
      "As principais aplicações que podem ser construídas com LLMs incluem:\n",
      "\n",
      "1. Criação e aprimoramento de conteúdo, como:\n",
      " * Geração de conteúdo: produção automática de texto\n",
      " * Assistência na redação: correção ortográfica, de estilo e de conteúdo\n",
      " * Tradução automática: conversão de texto de um idioma para outro\n",
      " * Resumo de textos: redução de documentos longos em resumos\n",
      " * Planejamento e roteiro de conteúdo: estruturação do conteúdo\n",
      " * Brainstorming: propostas criativas para projetos, nomes, conceitos, etc.\n",
      " * Programação: criação de código de programação a partir de linguagem natural\n",
      "\n",
      "2. Análise e organização de informações, como:\n",
      " * Análise de sentimento: avaliação de emoções e opiniões em textos\n",
      " * Extração de informações: extração de dados específicos de documentos grandes\n",
      " * Classificação de textos: organização de textos em categorias ou temas específicos\n",
      " * Revisão técnica: assistência na revisão de documentos especializados\n",
      "\n",
      "3. Interação e automação, como:\n",
      " * Chatbots: simulação de conversas sobre tópicos gerais ou específicos\n",
      " * Perguntas e respostas: geração de respostas a perguntas com base em um corpus\n",
      "\n",
      "Além disso, com o surgimento dos LLMs multimodais, outras aplicações estão começando a surgir, como a geração de conteúdo audiovisual, a interpretação de dados de imagens, a tradução de conteúdo multimídia ou a criação de experiências interativas ricas.\n",
      "=== Calling Function ===\n",
      "Calling function: artigo_engine with args: {\"input\": \"Quais as principais aplica\\u00e7\\u00f5es posso construir com LLMs e LangChain?\"}\n",
      "=== Function Output ===\n",
      "Com LLMs, você pode desenvolver aplicativos prontos para produção, como modelos de linguagem personalizados para atender às necessidades específicas do seu domínio. Além disso, você pode ajustar os modelos de código aberto para melhorar o desempenho em seu domínio específico. Isso permite que você crie soluções personalizadas para problemas como processamento de linguagem natural, geração de texto e análise de dados. Com a combinação de LLMs e ferramentas como a Databricks, você pode criar soluções robustas e escaláveis que atendam às suas necessidades de negócios.\n"
     ]
    }
   ],
   "source": [
    "response = agent_document.chat(\n",
    "    \"Quais as principais aplicações posso construir com LLMs e LangChain?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Quais as principais tendências em LangChain e LLM?\n",
      "=== Calling Function ===\n",
      "Calling function: artigo_engine with args: {\"input\": \"Quais as principais tend\\u00eancias em LangChain e LLM?\"}\n",
      "=== Function Output ===\n",
      "Não há informações sobre tendências em LangChain e LLM. No entanto, para começar a usar LLMs, existem algumas opções disponíveis, como assistir a apresentações sob demanda, participar de cursos sobre LLMs ou explorar exemplos de código para desenvolver aplicativos prontos para produção com LLMs.\n",
      "=== Calling Function ===\n",
      "Calling function: tutorial_engine with args: {\"input\": \"Quais as principais tend\\u00eancias em LangChain e LLM?\"}\n",
      "=== Function Output ===\n",
      "As principais tendências em LangChain e LLM incluem a proliferação de LLMs de código aberto, que democratizou o acesso à tecnologia de ponta de processamento de linguagem, permitindo que pesquisadores, desenvolvedores e amadores experimentassem, personalizassem e implantassem soluções de IA com um investimento inicial mínimo. Além disso, a integração do LLM às ferramentas de desenvolvimento de software e de escritório está transformando a eficiência e a capacidade das empresas. Outra tendência é a evolução dos LLMs para além da simples previsão de texto, tornando-se aplicativos sofisticados em vários domínios, arquiteturas e modalidades, incluindo LLMs baseados em redes neurais recorrentes e transformers.\n",
      "=== Calling Function ===\n",
      "Calling function: artigo_engine with args: {\"input\": \"Quais as principais tend\\u00eancias em LangChain e LLM?\"}\n",
      "=== Function Output ===\n",
      "Não há informações sobre tendências em LangChain e LLM. No entanto, para começar a usar LLMs, existem algumas opções disponíveis, como assistir a apresentações sob demanda, participar de cursos sobre LLMs ou explorar exemplos de código para desenvolver aplicativos prontos para produção com LLMs.\n",
      "=== Calling Function ===\n",
      "Calling function: tutorial_engine with args: {\"input\": \"Quais as principais tend\\u00eancias em LangChain e LLM?\"}\n",
      "=== Function Output ===\n",
      "As principais tendências em LangChain e LLM incluem a proliferação de LLMs de código aberto, que democratizou o acesso à tecnologia de ponta de processamento de linguagem, permitindo que pesquisadores, desenvolvedores e amadores experimentassem, personalizassem e implantassem soluções de IA com um investimento inicial mínimo. Além disso, a integração do LLM às ferramentas de desenvolvimento de software e de escritório está transformando a eficiência e a capacidade das empresas. Outra tendência é a evolução dos LLMs para além da simples previsão de texto, tornando-se aplicativos sofisticados em vários domínios, arquiteturas e modalidades, incluindo LLMs baseados em redes neurais recorrentes (RNNs) e transformers.\n",
      "=== Calling Function ===\n",
      "Calling function: artigo_engine with args: {\"input\": \"Quais as principais tend\\u00eancias em LangChain e LLM?\"}\n",
      "=== Function Output ===\n",
      "Não há informações sobre tendências em LangChain e LLM no texto fornecido. O texto se concentra em fornecer opções para começar a usar LLMs, incluindo assistir a apresentações, fazer um curso e trabalhar com exemplos de código. Não há menção a tendências específicas em LangChain e LLM.\n"
     ]
    }
   ],
   "source": [
    "response = agent_document.chat(\n",
    "    \"Quais as principais tendências em LangChain e LLM?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent ReAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import ReActAgent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ReActAgent.from_tools(\n",
    "    query_engine_tools,\n",
    "    verbose=True,\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step d4cc8851-0099-47c0-8dd2-1a880635fed8. Step input: Quais as principais ferramentas usadas em LAngChain?\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: Portuguese. I need to use a tool to help me answer the question.\n",
      "Action: artigo_engine\n",
      "Action Input: {'input': 'Quais as principais ferramentas usadas em LangChain?'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: Não há menção às ferramentas usadas em LangChain no texto fornecido. O texto discute grandes modelos de linguagem (LLM), serviços proprietários como o ChatGPT e modelos de código aberto, mas não menciona LangChain ou suas ferramentas.\n",
      "\u001b[0m> Running step aa623f1b-2b32-4852-8e25-ab4b6e3fbf16. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: A ferramenta artigo_engine não forneceu informações suficientes sobre as principais ferramentas usadas em LangChain. Vou tentar novamente com a ferramenta tutorial_engine.\n",
      "Action: tutorial_engine\n",
      "Action Input: {'input': 'Quais as principais ferramentas usadas em LangChain?'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: Não há menção às principais ferramentas usadas em LangChain no texto fornecido. O texto discute sobre LLMs (Modelos de Linguagem Grande), sua evolução, aplicações e tipologias, mas não menciona LangChain ou suas ferramentas.\n",
      "\u001b[0m> Running step ce19d955-c6ea-4997-9bd8-d3554b582140. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: As ferramentas artigo_engine e tutorial_engine não forneceram informações suficientes sobre as principais ferramentas usadas em LangChain. Infelizmente, não tenho mais informações para fornecer uma resposta precisa.\n",
      "Answer: Desculpe, mas não foi possível encontrar informações sobre as principais ferramentas usadas em LangChain com as ferramentas disponíveis.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\n",
    "    \"Quais as principais ferramentas usadas em LAngChain?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step a0c4c1e6-6b3a-4252-b55a-866e30553cff. Step input: Quais as principais tendências em LAngChain que eu deveria estudar?\n",
      "\u001b[1;3;38;5;200mThought: O usuário está procurando por tendências em LangChain. Eu posso usar o artigo_engine para obter informações sobre as principais tendências em LangChain.\n",
      "Action: artigo_engine\n",
      "Action Input: {'input': 'principais tendências em LangChain'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: Não há menção específica às principais tendências em LangChain no texto fornecido. O texto discute os grandes modelos de linguagem (LLM), a importância de ter controle sobre os dados e a capacidade de ajustar modelos de código aberto para melhorar o desempenho em domínios específicos, mas não aborda o tópico de LangChain.\n",
      "\u001b[0m> Running step dc43290c-1f27-4c96-b92c-032b5fcb1e51. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: O artigo_engine não forneceu informações sobre as principais tendências em LangChain. Vou tentar usar o tutorial_engine para obter informações sobre as principais tendências em LangChain.\n",
      "Action: tutorial_engine\n",
      "Action Input: {'input': 'principais tendências em LangChain'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: Não há menção específica às principais tendências em LangChain no texto fornecido. No entanto, é possível identificar algumas tendências gerais relacionadas ao desenvolvimento e aplicação de Large Language Models (LLMs) que podem estar relacionadas ao conceito de LangChain.\n",
      "\n",
      "Algumas das tendências observadas incluem:\n",
      "\n",
      "1. **Democratização da tecnologia de IA**: A proliferação de LLMs de código aberto está democratizando o acesso à tecnologia de ponta de processamento de linguagem, permitindo que pesquisadores, desenvolvedores e amadores experimentem, personalizem e implantem soluções de IA com um investimento inicial mínimo.\n",
      "\n",
      "2. **Integração do LLM às ferramentas de desenvolvimento de software e de escritório**: A integração do LLM às ferramentas de desenvolvimento de software e de escritório está transformando a eficiência e a capacidade das empresas, com exemplos como o Microsoft 365 Copilot e o Google Workspace.\n",
      "\n",
      "3. **Diversificação de arquiteturas de LLM**: Os LLMs estão progredindo além da simples previsão de texto e se tornando aplicativos sofisticados em vários domínios, arquiteturas e modalidades, incluindo LLMs baseados em redes neurais recorrentes (RNNs) e transformers.\n",
      "\n",
      "4. **Avanço na regulamentação da IA**: Há uma preocupação crescente com as considerações e os desafios éticos apresentados pelo desenvolvimento e uso de LLMs, levando a um avanço na regulamentação da IA e da IA generativa em todo o mundo.\n",
      "\n",
      "Essas tendências podem estar relacionadas ao conceito de LangChain, mas não há informações específicas sobre o tema no texto fornecido.\n",
      "\u001b[0m> Running step 00b0f793-f3b5-47cb-9e84-943ed051f1ee. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: O tutorial_engine forneceu informações sobre tendências gerais relacionadas ao desenvolvimento e aplicação de Large Language Models (LLMs) que podem estar relacionadas ao conceito de LangChain. Embora não haja menção específica às principais tendências em LangChain, as tendências identificadas podem ser relevantes para o tema.\n",
      "Answer: Algumas das tendências gerais relacionadas ao desenvolvimento e aplicação de Large Language Models (LLMs) que podem estar relacionadas ao conceito de LangChain incluem a democratização da tecnologia de IA, a integração do LLM às ferramentas de desenvolvimento de software e de escritório, a diversificação de arquiteturas de LLM e o avanço na regulamentação da IA. Essas tendências podem ser relevantes para o tema de LangChain, mas não há informações específicas sobre o tema no texto fornecido.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\n",
    "    \"Quais as principais tendências em LAngChain que eu deveria estudar?\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
